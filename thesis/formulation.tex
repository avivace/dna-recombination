The entire software and documentation produced during the Stage experience and the thesis drafting, including initial and discarded attempts are available in a public Git \href{https://github.com/avivace/dna-recombination}{repository} \cite{avivace_repo} on GitHub.

\section{Tools}
The sperimental work of the Stage experience was done on a GNU/Linux Debian \texttt{buster/sid} workstation, making large of use of the shell and other tools:

\texttt{Git}, a distributed version control system, helped to keep track of every progress in the documents and the software produced.

\texttt{Python} \cite{Rossum:1995:PRM:869369} and its \texttt{IDLE} was used to quickly implement and experiment the algorithms and procedures. It's also the interface to the Gurobi interactive shell. \texttt{Ruby} was considered too.

\texttt{Gurobi Optimizer} \cite{gurobi} is a commercial optimization solver. It provides a Python interface to formulate linears problem and solve them in Python software.

The \texttt{TeX} typesetting engine (in the \texttt{LaTex} macros environment, with some some extensions like \texttt{BiBTex} and the \texttt{pdflatex} compiler) were used to produce the documentation, the thesis and the slides.

\section{Reduced artificial instance}
Working on the entire genomes sequences would be prohibitive for such approach, and many of the existent solutions make assumptions on the nature of the genomes, as we've seen.

We take into consideration a reduced instance, considering a shorter sequence and only the main events (Scrambling, Inversing, Overlapping).

A Python script which \textit{procedually} generates an instance of the problem with given specific characteristics has been developed:

This generator script takes the following parameters to shape the wanted instance:

\begin{itemize}
	\item MIC length
	\item MDS quantity
	\item Overlap size
	\item Inverse rate
\end{itemize}

The generated instance consists in:

\begin{itemize}
	\item A (randomised) MIC DNA sequence
	\item A rearrangement map containing positions, inversion flags and annotation for every MDS, Pointer in both MIC and MAC
	\item The resulting MAC sequence
\end{itemize}

Running \texttt{\$ python gen.py}, we get:
\begin{verbatim}
Generated instance:

MDS     Start   End
0       3       9
1       21      27
2       30      38
3       40      50
4       13      19

P       Start1  End1    Start2  End2
1       7       9       21      23
2       25      27      30      32
3       35      38      40      43
4       46      50      13      17

MIC     ---AAATAT----TGGAGG--ATCGGT---GTAGAATT--ATTTCGTGGA----------
               ^^    ^^^^    ^^  ^^   ^^   ^^^  ^^^   ^^^^
MAC     AAATATCGGTAGAATTTCGTGGAGG
            ^^  ^^   ^^^   ^^^^
\end{verbatim}
The parameters used were:

\begin{itemize}
	\item $60$ as MAC length
	\item A random value in the $2-5$ range as MDS quantity
	\item $0$ as Inverse rate
	\item $30\%$ as Overlap size
\end{itemize}

The pointer regions are marked in both MIC and MAC. IESs are masked for clarity. The complete annotation map is exposed through four produced objects: \texttt{MDS\_MAC}, \texttt{MDS\_Mic}, \texttt{Pointer\_MIC} and \texttt{Pointer\_MAC}, easily navigable to fetch any information about the simulated process, e.g., \texttt{Pointer\_MIC[1]["Start2"]} and \texttt{Pointer\_MIC[1]["End2"]} gives the position of the second occurrence of the first pointer section in the MIC. A JSON object, serialising this data is produced, too.

\section{ILP}
\input{ilp_formulation}

\section{Preprocessing}
This part of the software computes the value for some of the variables, taking the instance as input.

Some of the defined variables are \textit{4-dimensional MIC length $\times$ MIC length $\times$ MAC length $\times$ MAC length} arrays. The necessity of a sparse data structure was immediatly clear: \textit{Sparray}, a Python module \cite{sparray} for sparse n-dimensional arrays using \textit{dictionaries} supporting any number of dimensions and any size was chosen to support these variables.

The Read-Write performance on these objects is satisfying: 15 milion integer values are written in random indexes in a 150M $\times$ 150M $\times$ 150M $\times$ 150M \textit{4d sparray} in less than 20 seconds. The data can then be accessed using a notation similar to the standard array one (\texttt{Sparray[Index1, Index2, Index3, Index4]}). \textit{Eq} and {cwc} are populated during this phase, with a naive iterative algorithm.

Here we encounter our first big limitation of a \textit{pure} linear programming approach. Populating Eq and cwc in our test instance (60 characters long MIC) was trivial but this task becomes so expensive it's infeasible with even genome sequences of more than 1000 characters.

The subsequences matching part must be approached with an high performing alignment tool like \textit{BLAST}.

\section{Gurobi Implementation}
TODO

\section{Correctness}

\paragraph{Lemma.}
Suppose

$I$ to be an instance of the problem,

$P$ to be the ILP formulation associated to $I$,

$S$ to be an assignment to every variable of $P$ satisfying the constraints.

Then it's possible to build a solution for $I$ with cost equal to the objective function in $S$.

\paragraph{Proof.}
TODO


\section{Conclusions}

A \textit{pure} integer linear programming approach is clearly not possible given the magnitude of the data to process.

\paragraph{Improving the formulation}